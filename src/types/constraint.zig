// Core constraint types for the Ananke system
const std = @import("std");

/// Unique identifier for constraints
pub const ConstraintID = u64;

/// Categories of constraints that can be extracted and enforced
pub const ConstraintKind = enum {
    syntactic, // Code structure, formatting, naming
    type_safety, // Type annotations, null safety, generics
    semantic, // Data flow, control flow, side effects
    architectural, // Module boundaries, dependencies, layering
    operational, // Performance, memory, concurrency
    security, // Input validation, auth, dangerous ops
};

/// Severity levels for constraint violations
pub const Severity = enum {
    err, // Must be fixed (renamed from 'error' which is reserved)
    warning, // Should be addressed
    info, // Informational
    hint, // Suggestion
};

/// Sources from which constraints can be extracted
pub const ConstraintSource = enum {
    AST_Pattern, // Extracted from AST analysis
    Type_System, // From type annotations and inference
    Control_Flow, // From control flow analysis
    Data_Flow, // From data flow analysis
    Test_Mining, // Extracted from test code
    Documentation, // From docs and comments
    Telemetry, // From runtime metrics
    User_Defined, // Manually specified
    LLM_Analysis, // Generated by LLM analysis
};

/// Types of enforcement for constraints
pub const EnforcementType = enum {
    Syntactic, // Enforced at syntax level
    Structural, // Enforced at structure level
    Semantic, // Enforced at semantic level
    Performance, // Enforced for performance requirements
    Security, // Enforced for security requirements
};

/// Priority levels for constraint resolution
pub const ConstraintPriority = enum {
    Low,
    Medium,
    High,
    Critical,

    pub fn toNumeric(self: ConstraintPriority) u32 {
        return switch (self) {
            .Low => 0,
            .Medium => 1,
            .High => 2,
            .Critical => 3,
        };
    }
};

/// A single constraint that can be validated
pub const Constraint = struct {
    /// Unique identifier (auto-generated if not specified)
    id: ConstraintID = 0,

    /// Human-readable name
    name: []const u8,

    /// Detailed description
    description: []const u8,

    /// Category of constraint
    kind: ConstraintKind,

    /// Source of constraint
    source: ConstraintSource = .AST_Pattern,

    /// Type of enforcement (inferred from kind if not specified)
    enforcement: EnforcementType = .Syntactic,

    /// Priority for conflict resolution
    priority: ConstraintPriority = .Medium,

    /// Confidence level (0.0 to 1.0)
    confidence: f32 = 1.0,

    /// Frequency of occurrence in codebase
    frequency: u32 = 1,

    /// Severity level
    severity: Severity,

    // Provenance information
    origin_file: ?[]const u8 = null,
    origin_line: ?u32 = null,
    created_at: i64 = 0,

    // Function pointers for constraint operations (typed holes)
    validate: ?*const fn (token: []const u8) bool = null,
    compile_fn: ?*const fn (self: *const Constraint) ConstraintIR = null,

    /// Initialize a new constraint with required fields
    pub fn init(
        id: ConstraintID,
        name: []const u8,
        description: []const u8,
    ) Constraint {
        return .{
            .id = id,
            .name = name,
            .description = description,
            .kind = .syntactic,
            .source = .AST_Pattern,
            .enforcement = .Syntactic,
            .priority = .Medium,
            .confidence = 1.0,
            .frequency = 1,
            .severity = .err,
            .created_at = std.time.timestamp(),
        };
    }

    /// Validate the constraint's internal consistency
    pub fn isValid(self: *const Constraint) bool {
        // Check confidence is in valid range
        if (self.confidence < 0.0 or self.confidence > 1.0) {
            return false;
        }

        // Check name is not empty
        if (self.name.len == 0) {
            return false;
        }

        // Check enforcement type matches kind
        const valid_enforcement = switch (self.kind) {
            .syntactic => self.enforcement == .Syntactic,
            .type_safety => self.enforcement == .Structural or self.enforcement == .Semantic,
            .semantic => self.enforcement == .Semantic,
            .operational => self.enforcement == .Performance,
            .security => self.enforcement == .Security,
            .architectural => self.enforcement == .Structural,
        };

        return valid_enforcement;
    }

    /// Get numeric priority value for sorting
    pub fn getPriorityValue(self: *const Constraint) u32 {
        return self.priority.toNumeric();
    }
};

/// Compiled constraint representation for efficient validation
pub const ConstraintIR = struct {
    /// JSON Schema for structured constraints
    json_schema: ?JsonSchema = null,

    /// Context-free grammar for syntax constraints
    grammar: ?Grammar = null,

    /// Regular expression patterns
    regex_patterns: []const Regex = &.{},

    /// Direct token masking rules
    token_masks: ?TokenMaskRules = null,

    /// Priority for conflict resolution
    priority: u32 = 0,

    /// true if this IR owns grammar strings (from clone), false if borrowed from interner
    owns_grammar_strings: bool = false,

    /// Free all allocated memory in this ConstraintIR
    pub fn deinit(self: *ConstraintIR, allocator: std.mem.Allocator) void {
        // Free json_schema if present
        if (self.json_schema) |*schema| {
            // Free the type string
            allocator.free(schema.type);

            // Free the properties ObjectMap
            if (schema.properties) |*props| {
                var iter = props.iterator();
                while (iter.next()) |entry| {
                    allocator.free(entry.key_ptr.*);
                    freeJsonValue(allocator, entry.value_ptr.*);
                }
                // Free the HashMap's backing storage
                props.deinit();
            }

            // Free the required array and its strings
            for (schema.required) |req| {
                allocator.free(req);
            }
            if (schema.required.len > 0) {
                allocator.free(schema.required);
            }
        }

        // Free grammar rules if present and owned
        if (self.grammar) |grammar| {
            if (self.owns_grammar_strings) {
                // We own the strings - free them
                allocator.free(grammar.start_symbol);
                for (grammar.rules) |rule| {
                    allocator.free(rule.lhs);
                    for (rule.rhs) |rhs_item| {
                        allocator.free(rhs_item);
                    }
                    allocator.free(rule.rhs);
                }
            } else {
                // We don't own the strings (borrowed from interner) - just free slices
                for (grammar.rules) |rule| {
                    allocator.free(rule.rhs);
                }
            }
            allocator.free(grammar.rules);
        }

        // Free regex patterns if present
        for (self.regex_patterns) |pattern| {
            // Only free non-static patterns
            if (!pattern.is_static) {
                allocator.free(pattern.pattern);
                if (pattern.flags.len > 0) {
                    allocator.free(pattern.flags);
                }
            }
        }
        if (self.regex_patterns.len > 0) {
            allocator.free(self.regex_patterns);
        }

        // Free token masks if present
        if (self.token_masks) |masks| {
            if (masks.allowed_tokens) |tokens| {
                allocator.free(tokens);
            }
            if (masks.forbidden_tokens) |tokens| {
                allocator.free(tokens);
            }
        }
    }

    /// Serialize to format compatible with llguidance
    pub fn serialize(self: ConstraintIR, allocator: std.mem.Allocator) ![]u8 {
        // TODO: Implement serialization to llguidance format
        _ = allocator;
        _ = self;
        return error.NotImplemented;
    }

    /// Create a deep clone of this ConstraintIR with independent ownership.
    /// Caller owns the returned ConstraintIR and must call deinit() on it.
    pub fn clone(self: *const ConstraintIR, allocator: std.mem.Allocator) !ConstraintIR {
        var cloned = ConstraintIR{
            .priority = self.priority,
            .owns_grammar_strings = true, // cloned IR owns its own strings
        };

        // Clone json_schema if present
        if (self.json_schema) |schema| {
            cloned.json_schema = try cloneJsonSchema(allocator, schema);
        }

        // Clone grammar if present
        if (self.grammar) |grammar| {
            cloned.grammar = try cloneGrammar(allocator, grammar);
        }

        // Clone regex_patterns array
        if (self.regex_patterns.len > 0) {
            const patterns = try allocator.alloc(Regex, self.regex_patterns.len);
            for (self.regex_patterns, 0..) |pattern, i| {
                if (pattern.is_static) {
                    // Static patterns: just copy the pointer, don't duplicate
                    patterns[i] = .{
                        .pattern = pattern.pattern,
                        .flags = pattern.flags,
                        .is_static = true,
                    };
                } else {
                    // Non-static patterns: duplicate the strings
                    patterns[i] = .{
                        .pattern = try allocator.dupe(u8, pattern.pattern),
                        .flags = try allocator.dupe(u8, pattern.flags),
                        .is_static = false,
                    };
                }
            }
            cloned.regex_patterns = patterns;
        }

        // Clone token_masks if present
        if (self.token_masks) |masks| {
            cloned.token_masks = try cloneTokenMasks(allocator, masks);
        }

        return cloned;
    }
};

/// Helper function to clone JsonSchema
fn cloneJsonSchema(allocator: std.mem.Allocator, schema: JsonSchema) !JsonSchema {
    var cloned = JsonSchema{
        .type = try allocator.dupe(u8, schema.type),
        .additional_properties = schema.additional_properties,
    };

    // Clone properties if present
    if (schema.properties) |props| {
        var cloned_props = std.json.ObjectMap.init(allocator);
        var iter = props.iterator();
        while (iter.next()) |entry| {
            const key = try allocator.dupe(u8, entry.key_ptr.*);
            const value = try cloneJsonValue(allocator, entry.value_ptr.*);
            try cloned_props.put(key, value);
        }
        cloned.properties = cloned_props;
    }

    // Clone required array
    if (schema.required.len > 0) {
        const required = try allocator.alloc([]const u8, schema.required.len);
        for (schema.required, 0..) |req, i| {
            required[i] = try allocator.dupe(u8, req);
        }
        cloned.required = required;
    }

    return cloned;
}

/// Helper function to clone a JSON value
fn cloneJsonValue(allocator: std.mem.Allocator, value: std.json.Value) !std.json.Value {
    return switch (value) {
        .null => .null,
        .bool => |b| .{ .bool = b },
        .integer => |i| .{ .integer = i },
        .float => |f| .{ .float = f },
        .number_string => |s| .{ .number_string = try allocator.dupe(u8, s) },
        .string => |s| .{ .string = try allocator.dupe(u8, s) },
        .array => |arr| {
            var cloned_arr = std.json.Array.init(allocator);
            for (arr.items) |item| {
                try cloned_arr.append(try cloneJsonValue(allocator, item));
            }
            return .{ .array = cloned_arr };
        },
        .object => |obj| {
            var cloned_obj = std.json.ObjectMap.init(allocator);
            var iter = obj.iterator();
            while (iter.next()) |entry| {
                const key = try allocator.dupe(u8, entry.key_ptr.*);
                const val = try cloneJsonValue(allocator, entry.value_ptr.*);
                try cloned_obj.put(key, val);
            }
            return .{ .object = cloned_obj };
        },
    };
}

/// Helper function to free a JSON value recursively
fn freeJsonValue(allocator: std.mem.Allocator, value: std.json.Value) void {
    switch (value) {
        .null, .bool, .integer, .float => {}, // No allocation
        .number_string => |s| allocator.free(s),
        .string => |s| allocator.free(s),
        .array => |arr| {
            for (arr.items) |item| {
                freeJsonValue(allocator, item);
            }
            // Note: arr.deinit() would free the ArrayList backing storage,
            // but we're managing memory manually here
        },
        .object => |obj| {
            var iter = obj.iterator();
            while (iter.next()) |entry| {
                allocator.free(entry.key_ptr.*);
                freeJsonValue(allocator, entry.value_ptr.*);
            }
            // Note: obj.deinit() would free the HashMap backing storage,
            // but we're managing memory manually here
        },
    }
}

/// Helper function to clone Grammar
fn cloneGrammar(allocator: std.mem.Allocator, grammar: Grammar) !Grammar {
    const rules = try allocator.alloc(GrammarRule, grammar.rules.len);

    for (grammar.rules, 0..) |rule, i| {
        const lhs = try allocator.dupe(u8, rule.lhs);

        const rhs = try allocator.alloc([]const u8, rule.rhs.len);
        for (rule.rhs, 0..) |rhs_item, j| {
            rhs[j] = try allocator.dupe(u8, rhs_item);
        }

        rules[i] = .{
            .lhs = lhs,
            .rhs = rhs,
        };
    }

    return Grammar{
        .rules = rules,
        .start_symbol = try allocator.dupe(u8, grammar.start_symbol),
    };
}

/// Helper function to clone TokenMaskRules
fn cloneTokenMasks(allocator: std.mem.Allocator, masks: TokenMaskRules) !TokenMaskRules {
    var cloned = TokenMaskRules{};

    if (masks.allowed_tokens) |tokens| {
        const allowed = try allocator.alloc(u32, tokens.len);
        @memcpy(allowed, tokens);
        cloned.allowed_tokens = allowed;
    }

    if (masks.forbidden_tokens) |tokens| {
        const forbidden = try allocator.alloc(u32, tokens.len);
        @memcpy(forbidden, tokens);
        cloned.forbidden_tokens = forbidden;
    }

    return cloned;
}

/// JSON Schema representation
pub const JsonSchema = struct {
    type: []const u8,
    properties: ?std.json.ObjectMap = null,
    required: []const []const u8 = &.{},
    additional_properties: bool = true,
};

/// Context-free grammar
pub const Grammar = struct {
    rules: []const GrammarRule,
    start_symbol: []const u8,
};

pub const GrammarRule = struct {
    lhs: []const u8,
    rhs: []const []const u8,
};

/// Regular expression pattern
pub const Regex = struct {
    pattern: []const u8,
    flags: []const u8 = "",
    is_static: bool = false, // true if pattern points to static RegexPatternPool constant
};

/// Individual token mask rule
pub const TokenMaskRule = struct {
    mask_type: MaskType,
    pattern: []const u8,
    description: []const u8,

    pub const MaskType = enum {
        allow_tokens,
        deny_tokens,
        require_tokens,
    };
};

/// Token masking rules for llguidance
pub const TokenMaskRules = struct {
    allowed_tokens: ?[]const u32 = null,
    forbidden_tokens: ?[]const u32 = null,

    /// Apply mask to token probabilities
    pub fn apply(self: TokenMaskRules, logits: []f32) void {
        if (self.forbidden_tokens) |forbidden| {
            for (forbidden) |token_id| {
                logits[token_id] = -std.math.inf(f32);
            }
        }

        if (self.allowed_tokens) |allowed| {
            // Set all non-allowed tokens to -inf
            for (logits, 0..) |*logit, i| {
                var is_allowed = false;
                for (allowed) |token_id| {
                    if (i == token_id) {
                        is_allowed = true;
                        break;
                    }
                }
                if (!is_allowed) {
                    logit.* = -std.math.inf(f32);
                }
            }
        }
    }
};

/// A collection of constraints
pub const ConstraintSet = struct {
    constraints: std.ArrayList(Constraint),
    name: []const u8,
    allocator: std.mem.Allocator,

    pub fn init(allocator: std.mem.Allocator, name: []const u8) ConstraintSet {
        return .{
            .constraints = std.ArrayList(Constraint){},
            .name = name,
            .allocator = allocator,
        };
    }

    pub fn deinit(self: *ConstraintSet) void {
        // Note: Currently does not free individual constraint string fields
        // This is intentional - constraints may use static string literals (from Clew)
        // or allocated strings (from JSON parsing). For JSON-parsed constraints,
        // use an arena allocator that gets freed separately.
        self.constraints.deinit(self.allocator);
    }

    pub fn add(self: *ConstraintSet, constraint: Constraint) !void {
        try self.constraints.append(self.allocator, constraint);
    }

    /// Clone this ConstraintSet, creating a deep copy with independent ownership.
    /// Caller owns the returned ConstraintSet and must call deinit() on it.
    pub fn clone(self: *const ConstraintSet, allocator: std.mem.Allocator) !ConstraintSet {
        // Deep copy the name to avoid dangling pointer
        const owned_name = try allocator.dupe(u8, self.name);
        errdefer allocator.free(owned_name);

        var cloned = ConstraintSet.init(allocator, owned_name);

        // Deep copy all constraints
        for (self.constraints.items) |constraint| {
            try cloned.constraints.append(allocator, constraint);
        }

        return cloned;
    }

    pub fn compile(self: ConstraintSet, allocator: std.mem.Allocator) !ConstraintIR {
        // TODO: Implement constraint compilation
        _ = allocator;
        _ = self;
        return error.NotImplemented;
    }
};
